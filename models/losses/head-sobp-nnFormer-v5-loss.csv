Epoch,Training Loss,Validation Loss
0,0.1943197789062795,0.09203020522468969
1,0.12462387532976113,0.06628988526369396
2,0.11558399726881792,0.056653261380760295
3,0.11038400330825855,0.05323177174125847
4,0.107011097336286,0.049947606889825115
5,0.10155816834518,0.04779101065114925
6,0.10002330587686677,0.04718637819352903
7,0.09857989977555055,0.045272246689388625
8,0.09852912946065005,0.04561673389061501
9,0.0962879435208283,0.046032667062000224
10,0.0952409326687063,0.04299985284083768
11,0.0939975162036717,0.042791052084220085
12,0.0891641722256808,0.04040410805885729
13,0.09960419493482302,0.03624904969413029
14,0.0789654103941039,0.03289176719753366
15,0.06903307551616117,0.03045227138423606
16,0.061464225138096434,0.03018745000621206
17,0.04469983484350929,0.025423850177934294
18,0.03471829508137154,0.029164237117296772
19,nan,nan
20,nan,nan
21,nan,nan
22,nan,nan
23,nan,nan
24,nan,nan
25,nan,nan
26,nan,nan
27,nan,nan
28,nan,nan
29,nan,nan
30,nan,nan
31,nan,nan
32,nan,nan
33,nan,nan
34,nan,nan
35,nan,nan
36,nan,nan
37,nan,nan
38,nan,nan
39,nan,nan
40,nan,nan
41,nan,nan
42,nan,nan
43,nan,nan
44,nan,nan
45,nan,nan
46,nan,nan
47,nan,nan
48,nan,nan
49,nan,nan
50,nan,nan
51,nan,nan
52,nan,nan
53,nan,nan
54,nan,nan
55,nan,nan
56,nan,nan
57,nan,nan
58,nan,nan
59,nan,nan
60,nan,nan
61,nan,nan
62,nan,nan
63,nan,nan
64,nan,nan
65,nan,nan
66,nan,nan
67,nan,nan
68,nan,nan
69,nan,nan
70,nan,nan
71,nan,nan
72,nan,nan
73,nan,nan
74,nan,nan
75,nan,nan
76,nan,nan
77,nan,nan
