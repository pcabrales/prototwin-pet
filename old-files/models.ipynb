{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMCKQt7mxaDe0SA+m+kQXvb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"6IBBjD2iq244"},"outputs":[],"source":["class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","\n","        self.activation = nn.Mish()  # Activation function\n","        self.pool = nn.MaxPool3d(2, stride=2)  # Pooling\n","\n","        # Encoder layers\n","\n","        self.e11 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n","        self.e12 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","        self.e21 = nn.Conv3d(16, 64, kernel_size=3, padding=1)\n","        self.e22 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        # Middle layers\n","\n","        self.m1 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n","        self.m2 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","\n","        # Decoder layers\n","\n","        self.upconv1 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2, output_padding=(1, 0, 1))  # Upscaling\n","        self.d11 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n","        self.d12 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        self.upconv2 = nn.ConvTranspose3d(64, 48, kernel_size=2, stride=2)  # Upscaling\n","        self.d21 = nn.Conv3d(64, 16, kernel_size=3, padding=1)\n","        self.d22 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","        self.output = nn.Conv3d(16, 1, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","\n","        x_e11 = self.activation(self.e11(x))\n","        x_e12 = self.activation(self.e12(x_e11))\n","        x_pool1 = self.pool(x_e12)\n","\n","        x_e21 = self.activation(self.e12(x_pool1))\n","        x_e22 = self.activation(self.e21(x_e21))\n","        x_pool2 = self.pool(x_e22)\n","\n","        x_m1 = self.activation(self.m1(x_pool2))\n","        x_m2 = self.activation(self.m2(x_m1))\n","\n","        x_upconv1 = self.upconv1(x_m2)\n","        x_upconv1 = torch.cat([x_upconv1, x_e22], dim=1)  # Concatenating\n","        x_d11 = self.activation(self.d11(x_upconv1))\n","        x_d12 = self.activation(self.d12(x_d11))\n","\n","        x_upconv2 = self.upconv2(x_d12)\n","        x_upconv2 = torch.cat([x_upconv2, x_e12], dim=1)  # Concatenating\n","        x_d21 = self.activation(self.d21(x_upconv2))\n","        x_d22 = self.activation(self.d22(x_d21))\n","\n","        x_out = self.output(x_d22)\n","\n","        return x_out.squeeze(1)\n","\n","\n","# Create the model\n","model = UNet().to(device)"]},{"cell_type":"code","source":["class UNetV2(nn.Module):\n","    def __init__(self):\n","        super(UNetV2, self).__init__()\n","\n","        self.activation = nn.Mish()  # Activation function\n","        self.pool = nn.MaxPool3d(2, stride=2)  # Pooling\n","        self.dropout = nn.Dropout3d(0.2)  # Dropout\n","\n","        # Encoder layers\n","\n","        self.e11 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n","        self.e12 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","        self.e21 = nn.Conv3d(16, 64, kernel_size=3, padding=1)\n","        self.e22 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        # Middle layers\n","\n","        self.m1 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n","        self.m2 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","\n","        # Decoder layers\n","\n","        self.upconv1 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2, output_padding=(1, 0, 1))  # Upscaling\n","        self.d11 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n","        self.d12 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        self.upconv2 = nn.ConvTranspose3d(64, 48, kernel_size=2, stride=2)  # Upscaling\n","        self.d21 = nn.Conv3d(64, 16, kernel_size=3, padding=1)\n","        self.d22 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","        self.output = nn.Conv3d(16, 1, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","\n","        x_e11 = self.activation(self.e11(x))\n","        x_e12 = self.activation(self.e12(x_e11))\n","        x_pool1 = self.pool(x_e12)\n","\n","        x_e21 = self.dropout(self.activation(self.e12(x_pool1)))\n","        x_e22 = self.dropout(self.activation(self.e21(x_e21)))\n","        x_pool2 = self.pool(x_e22)\n","\n","        x_m1 = self.activation(self.m1(x_pool2))\n","        x_m2 = self.activation(self.m2(x_m1))\n","\n","        x_upconv1 = self.upconv1(x_m2)\n","        x_upconv1 = torch.cat([x_upconv1, x_e22], dim=1)  # Concatenating\n","        x_d11 = self.activation(self.d11(x_upconv1))\n","        x_d12 = self.activation(self.d12(x_d11))\n","\n","        x_upconv2 = self.upconv2(x_d12)\n","        x_upconv2 = torch.cat([x_upconv2, x_e12], dim=1)  # Concatenating\n","        x_d21 = self.activation(self.d21(x_upconv2))\n","        x_d22 = self.activation(self.d22(x_d21))\n","\n","        x_out = self.output(x_d22)\n","\n","        return x_out.squeeze(1)\n"],"metadata":{"id":"wV3HcBtM9YDm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UNetV3(nn.Module):\n","    def __init__(self):\n","        super(UNetV3, self).__init__()\n","\n","        self.activation = nn.Mish()  # Activation function\n","        self.pool = nn.MaxPool3d(2, stride=2)  # Pooling\n","        self.dropout = nn.Dropout3d(0.2)  # Dropout\n","\n","        # Encoder layers\n","\n","        self.e11 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n","        self.e12 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","        self.e21 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n","        self.e22 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","\n","        self.e31 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n","        self.e32 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        # Middle layers\n","\n","        self.m1 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n","        self.m2 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","\n","        # Decoder layers\n","\n","        self.upconv1 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2, output_padding=1)  # Upscaling\n","        self.d11 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n","        self.d12 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        self.upconv2 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2, output_padding=(1, 0, 1))  # Upscaling\n","        self.d21 = nn.Conv3d(64, 32, kernel_size=3, padding=1)\n","        self.d22 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","\n","        self.upconv3 = nn.ConvTranspose3d(32, 16, kernel_size=2, stride=2)  # Upscaling\n","        self.d31 = nn.Conv3d(32, 16, kernel_size=3, padding=1)\n","        self.d32 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","\n","        self.output = nn.Conv3d(16, 1, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","\n","        x_e11 = self.activation(self.e11(x))\n","        x_e12 = self.activation(self.e12(x_e11))\n","        x_pool1 = self.pool(x_e12)\n","\n","        x_e21 = self.activation(self.e21(x_pool1))\n","        x_e22 = self.activation(self.e22(x_e21))\n","        x_pool2 = self.pool(x_e22)\n","\n","        x_e31 = self.activation(self.e31(x_pool2))\n","        x_e32 = self.activation(self.e32(x_e31))\n","        x_pool3 = self.pool(x_e32)\n","\n","        x_m1 = self.activation(self.m1(x_pool3))\n","        x_m2 = self.activation(self.m2(x_m1))\n","\n","        x_upconv1 = self.upconv1(x_m2)\n","        x_upconv1 = torch.cat([x_upconv1, x_e32], dim=1)  # Concatenating\n","        x_d11 = self.activation(self.d11(x_upconv1))\n","        x_d12 = self.activation(self.d12(x_d11))\n","\n","        x_upconv2 = self.upconv2(x_d12)\n","        x_upconv2 = torch.cat([x_upconv2, x_e22], dim=1)  # Concatenating\n","        x_d21 = self.activation(self.d21(x_upconv2))\n","        x_d22 = self.activation(self.d22(x_d21))\n","\n","        x_upconv3 = self.upconv3(x_d22)\n","        x_upconv3 = torch.cat([x_upconv3, x_e12], dim=1)  # Concatenating\n","        x_d31 = self.activation(self.d31(x_upconv3))\n","        x_d32 = self.activation(self.d32(x_d31))\n","\n","        x_out = self.output(x_d32)\n","\n","        return x_out.squeeze(1)\n","\n","\n","# Create the model\n","model = UNetV3().to(device)"],"metadata":{"id":"sJqzsVnL9UE9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UNetV4(nn.Module):\n","    def __init__(self):\n","        super(UNetV5, self).__init__()\n","\n","        self.activation = nn.Mish()  # Activation function\n","        self.pool = nn.MaxPool3d(2, stride=2)  # Pooling\n","        self.dropout = nn.Dropout3d(0.3)  # Dropout\n","\n","        # Encoder layers\n","\n","        self.e11 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n","        self.e12 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","        self.e21 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n","        self.e22 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","\n","        self.e31 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n","        self.e32 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        # Middle layers\n","\n","        self.m1 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n","        self.m2 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","\n","        # Decoder layers\n","\n","        self.upconv1 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2, output_padding=1)  # Upscaling\n","        self.d11 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n","        self.d12 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        self.upconv2 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2, output_padding=(1, 0, 1))  # Upscaling\n","        self.d21 = nn.Conv3d(64, 32, kernel_size=3, padding=1)\n","        self.d22 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","\n","        self.upconv3 = nn.ConvTranspose3d(32, 16, kernel_size=2, stride=2)  # Upscaling\n","        self.d31 = nn.Conv3d(32, 16, kernel_size=3, padding=1)\n","        self.d32 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","\n","        self.output = nn.Conv3d(16, 1, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","\n","        x_e11 = self.activation(self.e11(x))\n","        x_e12 = self.activation(self.e12(x_e11))\n","        x_pool1 = self.pool(x_e12)\n","\n","        x_e21 = self.activation(self.e21(x_pool1))\n","        x_e22 = self.dropout(self.activation(self.e22(x_e21)))\n","        x_pool2 = self.pool(x_e22)\n","\n","        x_e31 = self.dropout(self.activation(self.e31(x_pool2)))\n","        x_e32 = self.dropout(self.activation(self.e32(x_e31)))\n","        x_pool3 = self.pool(x_e32)\n","\n","        x_m1 = self.activation(self.m1(x_pool3))\n","        x_m2 = self.activation(self.m2(x_m1))\n","\n","        x_upconv1 = self.upconv1(x_m2)\n","        x_upconv1 = torch.cat([x_upconv1, x_e32], dim=1)  # Concatenating\n","        x_d11 = self.activation(self.d11(x_upconv1))\n","        x_d12 = self.activation(self.d12(x_d11))\n","\n","        x_upconv2 = self.upconv2(x_d12)\n","        x_upconv2 = torch.cat([x_upconv2, x_e22], dim=1)  # Concatenating\n","        x_d21 = self.activation(self.d21(x_upconv2))\n","        x_d22 = self.activation(self.d22(x_d21))\n","\n","        x_upconv3 = self.upconv3(x_d22)\n","        x_upconv3 = torch.cat([x_upconv3, x_e12], dim=1)  # Concatenating\n","        x_d31 = self.activation(self.d31(x_upconv3))\n","        x_d32 = self.activation(self.d32(x_d31))\n","\n","        x_out = self.output(x_d32)\n","\n","        return x_out.squeeze(1)\n","\n","\n","# Create the model\n","model = UNetV4().to(device)"],"metadata":{"id":"noThFv9iSYSV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UNetV5(nn.Module):\n","    def __init__(self):\n","        super(UNetV5, self).__init__()\n","\n","        self.activation = nn.Mish()  # Activation function\n","        self.pool = nn.MaxPool3d(2, stride=2)  # Pooling\n","\n","        # Encoder layers\n","\n","        self.e11 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n","        self.e12 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","        self.e21 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n","        self.e22 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","\n","        self.e31 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n","        self.e32 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        # Middle layers\n","\n","        self.m1 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n","        self.m2 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","\n","        # Decoder layers\n","\n","        self.upconv1 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2, output_padding=1)  # Upscaling\n","        self.d11 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n","        self.d12 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        self.upconv2 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2, output_padding=(1, 0, 1))  # Upscaling\n","        self.d21 = nn.Conv3d(64, 32, kernel_size=3, padding=1)\n","        self.d22 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","\n","        self.upconv3 = nn.ConvTranspose3d(32, 16, kernel_size=2, stride=2)  # Upscaling\n","        self.d31 = nn.Conv3d(32, 16, kernel_size=3, padding=1)\n","        self.d32 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","\n","        self.output = nn.Conv3d(16, 1, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","\n","        x_e11 = self.activation(self.e11(x))\n","        x_e12 = self.activation(self.e12(x_e11))\n","        x_pool1 = self.pool(x_e12)\n","\n","        x_e21 = self.activation(self.e21(x_pool1))\n","        x_e22 = self.activation(self.e22(x_e21))\n","        x_pool2 = self.pool(x_e22)\n","\n","        x_e31 = self.activation(self.e31(x_pool2))\n","        x_e32 = self.activation(self.e32(x_e31))\n","        x_pool3 = self.pool(x_e32)\n","\n","        x_m1 = self.activation(self.m1(x_pool3))\n","        x_m2 = self.activation(self.m2(x_m1))\n","\n","        x_upconv1 = self.upconv1(x_m2)\n","        x_upconv1 = torch.cat([x_upconv1, x_e32], dim=1)  # Concatenating\n","        x_d11 = self.activation(self.d11(x_upconv1))\n","        x_d12 = self.activation(self.d12(x_d11))\n","\n","        x_upconv2 = self.upconv2(x_d12)\n","        x_upconv2 = torch.cat([x_upconv2, x_e22], dim=1)  # Concatenating\n","        x_d21 = self.activation(self.d21(x_upconv2))\n","        x_d22 = self.activation(self.d22(x_d21))\n","\n","        x_upconv3 = self.upconv3(x_d22)\n","        x_upconv3 = torch.cat([x_upconv3, x_e12], dim=1)  # Concatenating\n","        x_d31 = self.activation(self.d31(x_upconv3))\n","        x_d32 = self.activation(self.d32(x_d31))\n","\n","        x_out = self.output(x_d32)\n","\n","        return x_out.squeeze(1)\n","\n","\n","# Create the model\n","model = UNetV5().to(device)"],"metadata":{"id":"OcVrfVYaUgWK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UNetV6(nn.Module):\n","    def __init__(self):\n","        super(UNetV6, self).__init__()\n","\n","        self.activation = nn.Mish()  # Activation function\n","        self.pool = nn.MaxPool3d(2, stride=2)  # Pooling\n","\n","        # Encoder layers\n","\n","        self.e11 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n","        self.e12 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","        self.e21 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n","        self.e22 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","\n","        self.e31 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n","        self.e32 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        self.e41 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n","        self.e42 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","\n","        # Middle layers\n","\n","        self.m1 = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n","        self.m2 = nn.Conv3d(256, 256, kernel_size=3, padding=1)\n","\n","        # Decoder layers\n","\n","        self.upconv1 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2, output_padding=(0, 1, 0))  # Upscaling\n","        self.d11 = nn.Conv3d(256, 128, kernel_size=3, padding=1)\n","        self.d12 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","\n","        self.upconv2 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2, output_padding=1)  # Upscaling\n","        self.d21 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n","        self.d22 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        self.upconv3 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2, output_padding=(1, 0, 1))  # Upscaling\n","        self.d31 = nn.Conv3d(64, 32, kernel_size=3, padding=1)\n","        self.d32 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","\n","        self.upconv4 = nn.ConvTranspose3d(32, 16, kernel_size=2, stride=2)  # Upscaling\n","        self.d41 = nn.Conv3d(32, 16, kernel_size=3, padding=1)\n","        self.d42 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","\n","\n","        self.output = nn.Conv3d(16, 1, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","\n","        x_e11 = self.activation(self.e11(x))\n","        x_e12 = self.activation(self.e12(x_e11))\n","        x_pool1 = self.pool(x_e12)\n","\n","        x_e21 = self.activation(self.e21(x_pool1))\n","        x_e22 = self.activation(self.e22(x_e21))\n","        x_pool2 = self.pool(x_e22)\n","\n","        x_e31 = self.activation(self.e31(x_pool2))\n","        x_e32 = self.activation(self.e32(x_e31))\n","        x_pool3 = self.pool(x_e32)\n","\n","        x_e41 = self.activation(self.e41(x_pool3))\n","        x_e42 = self.activation(self.e42(x_e41))\n","        x_pool4 = self.pool(x_e42)\n","\n","        x_m1 = self.activation(self.m1(x_pool4))\n","        x_m2 = self.activation(self.m2(x_m1))\n","\n","        x_upconv1 = self.upconv1(x_m2)\n","        x_upconv1 = torch.cat([x_upconv1, x_e42], dim=1)  # Concatenating\n","        x_d11 = self.activation(self.d11(x_upconv1))\n","        x_d12 = self.activation(self.d12(x_d11))\n","\n","        x_upconv2 = self.upconv2(x_d12)\n","        x_upconv2 = torch.cat([x_upconv2, x_e32], dim=1)  # Concatenating\n","        x_d21 = self.activation(self.d21(x_upconv2))\n","        x_d22 = self.activation(self.d22(x_d21))\n","\n","        x_upconv3 = self.upconv3(x_d22)\n","        x_upconv3 = torch.cat([x_upconv3, x_e22], dim=1)  # Concatenating\n","        x_d31 = self.activation(self.d31(x_upconv3))\n","        x_d32 = self.activation(self.d32(x_d31))\n","\n","        x_upconv4 = self.upconv4(x_d32)\n","        x_upconv4 = torch.cat([x_upconv4, x_e12], dim=1)  # Concatenating\n","        x_d41 = self.activation(self.d41(x_upconv4))\n","        x_d42 = self.activation(self.d42(x_d41))\n","\n","        x_out = self.output(x_d42)\n","\n","        return x_out.squeeze(1)\n","\n","\n","# Create the model\n","model = UNetV6().to(device)"],"metadata":{"id":"cu7UB0jD7Zl1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UNetV7(nn.Module):\n","    def __init__(self):\n","        super(UNetV7, self).__init__()\n","\n","        self.activation = nn.Mish()  # Activation function\n","        self.pool = nn.MaxPool3d(2, stride=2)  # Pooling\n","\n","        # Encoder layers\n","\n","        self.e11 = nn.Conv3d(1, 32, kernel_size=3, padding=1)\n","        self.e12 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","\n","        self.e21 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n","        self.e22 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        self.e31 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n","        self.e32 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","\n","        self.e41 = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n","        self.e42 = nn.Conv3d(256, 256, kernel_size=3, padding=1)\n","\n","        # Middle layers\n","\n","        self.m1 = nn.Conv3d(256, 512, kernel_size=3, padding=1)\n","        self.m2 = nn.Conv3d(512, 512, kernel_size=3, padding=1)\n","\n","        # Decoder layers\n","\n","        self.upconv1 = nn.ConvTranspose3d(512, 256, kernel_size=2, stride=2, output_padding=(0, 1, 0))  # Upscaling\n","        self.d11 = nn.Conv3d(512, 256, kernel_size=3, padding=1)\n","        self.d12 = nn.Conv3d(256, 256, kernel_size=3, padding=1)\n","\n","        self.upconv2 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2, output_padding=1)  # Upscaling\n","        self.d21 = nn.Conv3d(256, 128, kernel_size=3, padding=1)\n","        self.d22 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","\n","        self.upconv3 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2, output_padding=(1, 0, 1))  # Upscaling\n","        self.d31 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n","        self.d32 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","\n","        self.upconv4 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)  # Upscaling\n","        self.d41 = nn.Conv3d(64, 32, kernel_size=3, padding=1)\n","        self.d42 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","\n","\n","        self.output = nn.Conv3d(32, 1, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","\n","        x_e11 = self.activation(self.e11(x))\n","        x_e12 = self.activation(self.e12(x_e11))\n","        x_pool1 = self.pool(x_e12)\n","\n","        x_e21 = self.activation(self.e21(x_pool1))\n","        x_e22 = self.activation(self.e22(x_e21))\n","        x_pool2 = self.pool(x_e22)\n","\n","        x_e31 = self.activation(self.e31(x_pool2))\n","        x_e32 = self.activation(self.e32(x_e31))\n","        x_pool3 = self.pool(x_e32)\n","\n","        x_e41 = self.activation(self.e41(x_pool3))\n","        x_e42 = self.activation(self.e42(x_e41))\n","        x_pool4 = self.pool(x_e42)\n","\n","        x_m1 = self.activation(self.m1(x_pool4))\n","        x_m2 = self.activation(self.m2(x_m1))\n","\n","        x_upconv1 = self.upconv1(x_m2)\n","        x_upconv1 = torch.cat([x_upconv1, x_e42], dim=1)  # Concatenating\n","        x_d11 = self.activation(self.d11(x_upconv1))\n","        x_d12 = self.activation(self.d12(x_d11))\n","\n","        x_upconv2 = self.upconv2(x_d12)\n","        x_upconv2 = torch.cat([x_upconv2, x_e32], dim=1)  # Concatenating\n","        x_d21 = self.activation(self.d21(x_upconv2))\n","        x_d22 = self.activation(self.d22(x_d21))\n","\n","        x_upconv3 = self.upconv3(x_d22)\n","        x_upconv3 = torch.cat([x_upconv3, x_e22], dim=1)  # Concatenating\n","        x_d31 = self.activation(self.d31(x_upconv3))\n","        x_d32 = self.activation(self.d32(x_d31))\n","\n","        x_upconv4 = self.upconv4(x_d32)\n","        x_upconv4 = torch.cat([x_upconv4, x_e12], dim=1)  # Concatenating\n","        x_d41 = self.activation(self.d41(x_upconv4))\n","        x_d42 = self.activation(self.d42(x_d41))\n","\n","        x_out = self.output(x_d42)\n","\n","        return x_out.squeeze(1)\n","\n","\n","# Create the model\n","model = UNetV7().to(device)"],"metadata":{"id":"K2rqMoa0iI2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class UNetV9(nn.Module):\n","    def __init__(self):\n","        super(UNetV9, self).__init__()\n","\n","        self.activation = nn.Mish()  # Activation function\n","        self.pool = nn.MaxPool3d(2, stride=2)  # Pooling\n","\n","        # Encoder layers\n","\n","        self.e11 = nn.Conv3d(1, 16, kernel_size=3, padding=1)\n","        self.e_bn11 = nn.BatchNorm3d(16)\n","        self.e12 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","        self.e_bn12 = nn.BatchNorm3d(16)\n","\n","        self.e21 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n","        self.e_bn21 = nn.BatchNorm3d(32)\n","        self.e22 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","        self.e_bn22 = nn.BatchNorm3d(32)\n","\n","        self.e31 = nn.Conv3d(32, 64, kernel_size=3, padding=1)\n","        self.e_bn31 = nn.BatchNorm3d(64)\n","        self.e32 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","        self.e_bn32 = nn.BatchNorm3d(64)\n","\n","        self.e41 = nn.Conv3d(64, 128, kernel_size=3, padding=1)\n","        self.e_bn41 = nn.BatchNorm3d(128)\n","        self.e42 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","        self.e_bn42 = nn.BatchNorm3d(128)\n","\n","        # Middle layers\n","\n","        self.m1 = nn.Conv3d(128, 256, kernel_size=3, padding=1)\n","        self.m_bn1 = nn.BatchNorm3d(256)\n","        self.m2 = nn.Conv3d(256, 256, kernel_size=3, padding=1)\n","        self.m_bn2 = nn.BatchNorm3d(256)\n","\n","        # Decoder layers\n","\n","        self.upconv1 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2, output_padding=(0, 1, 0))  # Upscaling\n","        self.d11 = nn.Conv3d(256, 128, kernel_size=3, padding=1)\n","        self.d_bn11 = nn.BatchNorm3d(128)\n","        self.d12 = nn.Conv3d(128, 128, kernel_size=3, padding=1)\n","        self.d_bn12 = nn.BatchNorm3d(128)\n","\n","        self.upconv2 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2, output_padding=1)  # Upscaling\n","        self.d21 = nn.Conv3d(128, 64, kernel_size=3, padding=1)\n","        self.d_bn21 = nn.BatchNorm3d(64)\n","        self.d22 = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n","        self.d_bn22 = nn.BatchNorm3d(64)\n","\n","        self.upconv3 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2, output_padding=(1, 0, 1))  # Upscaling\n","        self.d31 = nn.Conv3d(64, 32, kernel_size=3, padding=1)\n","        self.d_bn31 = nn.BatchNorm3d(32)\n","        self.d32 = nn.Conv3d(32, 32, kernel_size=3, padding=1)\n","        self.d_bn32 = nn.BatchNorm3d(32)\n","\n","        self.upconv4 = nn.ConvTranspose3d(32, 16, kernel_size=2, stride=2)  # Upscaling\n","        self.d41 = nn.Conv3d(32, 16, kernel_size=3, padding=1)\n","        self.d_bn41 = nn.BatchNorm3d(16)\n","        self.d42 = nn.Conv3d(16, 16, kernel_size=3, padding=1)\n","        self.d_bn42 = nn.BatchNorm3d(16)\n","\n","\n","        self.output = nn.Conv3d(16, 1, kernel_size=3, padding=1)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","\n","        x_e11 = self.activation(self.e_bn11(self.e11(x)))\n","        x_e12 = self.activation(self.e_bn12(self.e12(x_e11)))\n","        x_pool1 = self.pool(x_e12)\n","\n","        x_e21 = self.activation(self.e_bn21(self.e21(x_pool1)))\n","        x_e22 = self.activation(self.e_bn22(self.e22(x_e21)))\n","        x_pool2 = self.pool(x_e22)\n","\n","        x_e31 = self.activation(self.e_bn31(self.e31(x_pool2)))\n","        x_e32 = self.activation(self.e_bn32(self.e32(x_e31)))\n","        x_pool3 = self.pool(x_e32)\n","\n","        x_e41 = self.activation(self.e_bn41(self.e41(x_pool3)))\n","        x_e42 = self.activation(self.e_bn42(self.e42(x_e41)))\n","        x_pool4 = self.pool(x_e42)\n","\n","        x_m1 = self.activation(self.m_bn1(self.m1(x_pool4)))\n","        x_m2 = self.activation(self.m_bn2(self.m2(x_m1)))\n","\n","        x_upconv1 = self.upconv1(x_m2)\n","        x_upconv1 = torch.cat([x_upconv1, x_e42], dim=1)  # Concatenating\n","        x_d11 = self.activation(self.d_bn11(self.d11(x_upconv1)))\n","        x_d12 = self.activation(self.d_bn12(self.d12(x_d11)))\n","\n","        x_upconv2 = self.upconv2(x_d12)\n","        x_upconv2 = torch.cat([x_upconv2, x_e32], dim=1)  # Concatenating\n","        x_d21 = self.activation(self.d_bn21(self.d21(x_upconv2)))\n","        x_d22 = self.activation(self.d_bn22(self.d22(x_d21)))\n","\n","        x_upconv3 = self.upconv3(x_d22)\n","        x_upconv3 = torch.cat([x_upconv3, x_e22], dim=1)  # Concatenating\n","        x_d31 = self.activation(self.d_bn31(self.d31(x_upconv3)))\n","        x_d32 = self.activation(self.d_bn32(self.d32(x_d31)))\n","\n","        x_upconv4 = self.upconv4(x_d32)\n","        x_upconv4 = torch.cat([x_upconv4, x_e12], dim=1)  # Concatenating\n","        x_d41 = self.activation(self.d_bn41((self.d41(x_upconv4))))\n","        x_d42 = self.activation(self.d_bn42(self.d42(x_d41)))\n","\n","        x_out = self.output(x_d42)\n","\n","        return x_out.squeeze(1)\n","\n","\n","# Create the model\n","model = UNetV9().to(device)"],"metadata":{"id":"JoUshaEEZlm0"},"execution_count":null,"outputs":[]}]}